# ðŸŽµ Beyond Parentheses : IML Audio Workstation

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)

**Personalizing Graphical Sound Captions through Interactive Machine Learning**

> **Note to Reviewers:** This repository contains the source code and implementation details for the Extended Abstract submitted to the **CHI 2026 Student Research Competition**.

---

<details open>
<summary><h2>ðŸ“– About the Research</h2></summary>

While speech captions are well-established, non-verbal sound captions (e.g., *"[suspenseful music]"*) often fail to convey the intuitive "texture" and temporal dynamics of audio. 

**"Beyond Parentheses"** proposes a parametric visual modality that translates auditory features into dynamic motion graphics. We utilize an **Interactive Machine Learning (IML)** approach, allowing users to correct the AI's interpretation and fine-tune the visualization model to match their subjective perception.

### ðŸ“„ Citation
If you find this work useful, please cite our CHI 2026 Extended Abstract:

```bibtex
@inproceedings{yang2026beyond,
  title={Beyond Parentheses: Personalizing Graphical Sound Captions through Interactive Machine Learning},
  author={Yang, Jiwon and Lee, Hwain},
  booktitle={CHI '26 Extended Abstracts: CHI Conference on Human Factors in Computing Systems Extended Abstracts},
  year={2026},
  publisher={ACM},
  address={New York, NY, USA}
}
