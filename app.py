import os
import json
import torch
import numpy as np
import librosa
import soundfile as sf
from flask import Flask, render_template, request, jsonify
from model import DualHeadNet
import torch.optim as optim
import torch.nn as nn

app = Flask(__name__, static_url_path='', static_folder='static', template_folder='static')

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---
UPLOAD_FOLDER = 'uploads'
DATA_FILE = 'data/training_data.json'
MODEL_FILE = 'best_model.pth'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs('data', exist_ok=True)

# ëª¨ë¸ ë¡œë“œ (CPU/GPU ìë™ ì„¤ì •)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = DualHeadNet().to(device)

def load_model():
    if os.path.exists(MODEL_FILE):
        try:
            model.load_state_dict(torch.load(MODEL_FILE, map_location=device))
            print("âœ… í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except:
            print("âš ï¸ ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ (ì´ˆê¸°í™” ìƒíƒœë¡œ ì‹œì‘)")
    
    model.eval() 
    print("ğŸ”’ ëª¨ë¸ì´ í‰ê°€ ëª¨ë“œ(Eval)ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

load_model()

# --- ë¼ìš°íŠ¸ ---

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload_analyze', methods=['POST'])
def upload_analyze():
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file part'}), 400
            
        file = request.files['file']
        filepath = os.path.join(UPLOAD_FOLDER, 'current.wav')
        file.save(filepath)
        
        # 1. ì „ì²´ ì˜¤ë””ì˜¤ ë¡œë“œ (ffmpeg ì„¤ì¹˜ë¨ ê°€ì •)
        try:
            y, sr = librosa.load(filepath, sr=22050)
        except Exception as e:
            print(f"Librosa load failed, trying audioread: {e}")
            # soundfile fallback
            data, samplerate = sf.read(filepath)
            if len(data.shape) > 1: data = np.mean(data, axis=1)
            if samplerate != 22050:
                y = librosa.resample(data, orig_sr=samplerate, target_sr=22050)
            else:
                y = data
            sr = 22050

        hop_length = 512
        
        # 2. íŠ¹ì§• ì¶”ì¶œ (Mel Spectrogram)
        mels = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=hop_length, n_mels=128)
        mels_db = librosa.power_to_db(mels, ref=np.max)
        
        # 3. í”„ë ˆì„ë³„ íŠ¹ì§• ë²¡í„° ìƒì„± ë° ì¶”ë¡ 
        frames_data = []
        total_frames = mels_db.shape[1]
        
        model.eval()
        
        with torch.no_grad():
            for i in range(total_frames):
                col = mels_db[:, i]
                
                # [í•µì‹¬ ìˆ˜ì •] numpy.float32 -> python float ê°•ì œ í˜•ë³€í™˜
                # JSON ì—ëŸ¬ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ float()ë¡œ ê°ì‹¸ì¤ë‹ˆë‹¤.
                f1 = float(np.mean(col[:32]))
                f2 = float(np.mean(col[32:64]))
                f3 = float(np.mean(col[64:96]))
                f4 = float(np.mean(col[96:]))
                
                # Normalize
                feat = [(x + 80) / 80 for x in [f1, f2, f3, f4]]
                
                input_tensor = torch.FloatTensor([feat]).to(device)
                
                # ëª¨ë¸ ì˜ˆì¸¡
                glyph_prob, params = model(input_tensor)
                
                glyph_idx = int(torch.argmax(glyph_prob, dim=1).item())
                param_vals = params.cpu().numpy()[0].tolist() # ì´ê±´ ì´ë¯¸ list(float)ë¼ ê´œì°®ìŒ
                
                frames_data.append({
                    'input': feat,
                    'glyph': glyph_idx,
                    'params': param_vals
                })

        print(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(frames_data)} í”„ë ˆì„")
        return jsonify({'frames': frames_data})

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/train_finetune', methods=['POST'])
def train_finetune():
    try:
        new_data = request.json
        if not new_data: return jsonify({'msg': 'No data'})

        # 1. ë°ì´í„° ì €ì¥
        existing_data = []
        if os.path.exists(DATA_FILE):
            with open(DATA_FILE, 'r') as f:
                try: existing_data = json.load(f)
                except: pass
        
        valid_data = [d for d in new_data if 'input' in d]
        
        formatted_data = []
        for d in valid_data:
            formatted_data.append({
                'input': d['input'],
                'label_glyph': d['glyph'],
                'label_params': d['params']
            })
            
        existing_data.extend(formatted_data)
        if len(existing_data) > 10000: existing_data = existing_data[-10000:]
            
        with open(DATA_FILE, 'w') as f:
            json.dump(existing_data, f)

        # 2. í•™ìŠµ (Fine-tuning)
        print(f"ğŸ”„ {len(formatted_data)}ê°œ í”„ë ˆì„ í•™ìŠµ ì‹œì‘...")
        
        inputs = torch.FloatTensor([d['input'] for d in formatted_data]).to(device)
        labels_g = torch.LongTensor([d['label_glyph'] for d in formatted_data]).to(device)
        labels_p = torch.FloatTensor([d['label_params'] for d in formatted_data]).to(device)
        
        model.train()
        optimizer = optim.Adam(model.parameters(), lr=0.005)
        crit_cls = nn.CrossEntropyLoss()
        crit_reg = nn.MSELoss()
        
        for epoch in range(20):
            optimizer.zero_grad()
            out_g, out_p = model(inputs)
            loss = crit_cls(out_g, labels_g) + crit_reg(out_p, labels_p)
            loss.backward()
            optimizer.step()
            
        torch.save(model.state_dict(), MODEL_FILE)
        model.eval() # ë‹¤ì‹œ í‰ê°€ ëª¨ë“œë¡œ
        print("âœ… ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ")

        return jsonify({'status': 'success'})
        
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì¤‘ ì—ëŸ¬: {e}")
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    # í¬íŠ¸ë¥¼ 5001ë¡œ ìœ ì§€ (ë§¥ë¶ AirPlay ìˆ˜ì‹ ê¸°ì™€ 5000í¬íŠ¸ ì¶©ëŒ ë°©ì§€ìš©)
    app.run(port=5001, debug=True)